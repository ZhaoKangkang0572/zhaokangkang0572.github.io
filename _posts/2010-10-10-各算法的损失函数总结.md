---
layout: post
title: 各算法的损失函数总结
category: MLTheory
tags: SVM
description: 
---
* content
{:toc}

#### SVM
1. 硬间隔
 目标有两个
 >1. 最大化间隔  $\min \limits_{w,b} \frac{1}{2}\|w\|^2$
 >2. 约束条件（使样本被正确分类） $y_i(w^Tx_i+b) \geq 1$
这时候只要转化问题，使用SMO算法求解，不需要损失函数

2. 软间隔
引入松弛变量之后，目标函数变为
$$
\min \limits_{w,b} \frac{1}{2}\|w\|^2+ \sum \limits_{i=1}^{n}\xi_i
$$
通常分类问题可以用$(0,1)$损失函数，但是他不是连续的，求导不好求，所以使用合页函数
$$
l_{hinge}=max(0,1-z)
$$
所以软间隔的目标函数为：
$$
\min \limits_{w,b} \frac{1}{2}\|w\|^2+ \sum \limits_{i=1}^{n}\xi_i \\
s.t. y_i(w^Tx_i+b) \geq 1-\xi_i \\
$$
其中
$$
\xi=max(0,1-y_i(w^Tx_i+b))
$$


