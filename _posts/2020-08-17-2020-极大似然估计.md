---
layout: post
title: 2020-08-17-2020-极大似然估计
category: DLTheory
tags: 
description: 
---

* content
{:toc}

#### 
1. 模型已定，参数也是固定的，但是未知
2.  我们通过若干次试验，观察其结果，利用得到的结果得到某个参数值能够**使这些样本都出现的概率为最大**
3.  每次实验独立，所以结果都符合独立同分布（因为模型参数确定，虽然未知）

给定样本
$D=\{x_1,x_2,...,x_N\}$

1. 写出似然函数，因为独立同分布，所以我们设联合概率密度函数$p(D|\theta)$为相对于样本$D=\{x_1,x_2,...,x_N\}$的$\theta$的似然函数
 $$l(\theta)=p(D|\theta)=p(x_1,x_2,...,x_N|\theta)=\prod \limits_{i=1}^Np(x_i|\theta)$$
 2. 我们的目标是求出参数空间中，能使得$l(\theta)$最大的参数值$\hat{\theta}$,记为
 
 $$\hat{\theta}(x_1,x_2,...,x_N):极大似然估计值$$  
 3. 求解
$$ \mathop{\arg\max}_{\theta}l(\theta)= \mathop{\arg\min}_{\theta}\prod \limits_{i=1}^{N}p(x_i|\theta)$$
为了便于计算定义对数似然函数
$$H(\theta)=\ln l(\theta)$$
$$ \hat{\theta}=\mathop{\arg\max}_{\theta}H(\theta)= \mathop{\arg\max}_{\theta}\ln l(\theta)= \mathop{\arg\min}_{\theta}\ln \prod \limits_{i=1}^{N}p(x_i|\theta)=\mathop{\arg\min}_{\theta} \sum \limits_{i=1}^{N}\ln p(x_i|\theta)$$
注意连乘变连加

> 3.1 $\theta$只有一个的情况下
> （要满足似然函数连续可微）
> $$\frac{\mathrm{d}{H(\theta)}}{\mathrm{\theta}}=0$$  

>3.2 $\theta$多个
>$$\theta=[\theta _1,\theta _2,...,\theta _S]^T$$
>记梯度算子：
> $$\nabla_\theta =[\frac{\partial}{\partial \theta_1},\frac{\partial}{\partial \theta_2},...,\frac{\partial}{\partial \theta_S}]$$
>下列方程的解就是最大似然估计量 $\hat{\theta}$
>$$\nabla _\theta H(\theta)=\nabla _\theta \ln l(\theta)=\sum \limits_{i=1}^{N}\nabla _\theta \ln P(x_i|\theta)=0$$


### 为什么环节

Q:为什么 这里的多个参数可以直接求，而逻辑回归的损失函数里，求极大似然是用梯度下降
A: 逻辑回归中极大似然函数无法直接求解，所以要用梯度下降来不断逼急最优解
>这里贴一个回答：线性回归有解析解为什么还要用梯度下降
>因为不能保证所选的特征是完全线性无关的，所以系数增广矩阵的秩小于n(n表示特征数),这导致虽然线性回归有解析解但是它有无穷多解（线性代数的知识），你还是无法求得一个准确的解，所以这个时候就用梯度下降法来逼近一个解。


Reference:
摘抄：https://blog.csdn.net/zengxiantao1994/article/details/72787849