---
layout: post
title: 2020-10-26-熵 
category: MLTheory
tags: 熵 KL散度 交叉熵
description: 
---
* content
{:toc}

$H(x)=\sum p(x_i)log(p(x_i))$

$D_{K||L}=\sum p(x_i)log(\frac {p(x_i)}{q(x_i)})$
$P(X)=[1,0,0]$
$Q(X)=[0.7,0.2,0.1]$

$\sum p(x_i)log(\frac {p(x_i)}{q(x_i)})=\sum p(x_i)\log p(x_i)-\sum p(x_i)\log q(x_i)$

其中
第一项就是熵，但是由于可以看作常量来忽略，因为是标签信息，已知
第二项就是交叉熵