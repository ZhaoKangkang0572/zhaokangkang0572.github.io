---
layout: post
title: SEE: Syntax-Aware Entity Embedding for Neural Relation Extraction
category: Extraction
tags: Paper Reading
description: extra entity Descriptions
---
@Author
Zhengqiu He,1 Wenliang Chen,1,4∗ Zhenghua Li Meishan Zhang,3 Wei Zhang,2 Min Zhang1


AAAI 2018

## 问题
1. 以往的神经网络抽取很少对实体进行语义方面的建模



## 解决方法
This paper propose to learn syntax-aware entity embedding for

Step 1:

Based on tree-GRU, they encode the context of entity on a dependency tree as sentence-level entity embedding.

Step 2:
使用intra-sentence and inter-sentence attentions在所有包含实体对的句子上面获取sentence set-level entity embedding

Step 3:
结合句向量和实体向量来做关系抽取。




<font color=#ff8C00>以前的工作通常只考虑到两个实体间的联系，并未考虑到实体所表示的意义， 这样子在遇到unknow 实体时行不通，但是当考虑了实体所表示的意义之后就不同了 </font>
## 模型



## 实验

![](../../graph/learningWithNoiseApproachOverview.png)

## 启发
考虑实体意义确实可以帮助unknow entity的识别，但是如何给entity编码是个大问题，必须让entity的内涵更加有用才行
