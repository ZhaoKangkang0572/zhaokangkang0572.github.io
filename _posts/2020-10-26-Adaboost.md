---
layout: post
title: Adaboost 
category: MLTheory
tags: Adaboost
description: Adaboost
---
* content
{:toc}


#### 总览
Adaptive Boosting：自适应增强
>自适应表现在：
1. 前一个分类器错误分类的样本的权值会增大，正确分类的样本权值会减小
2. 每轮迭代都会加入一个新的弱分类器



#### 步骤
1. 初始化样本的权值分布 $W_D=(\frac{1}{n},\frac{1}{n},\frac{1}{n},...,\frac{1}{n})$ 
2. 多轮迭代
a 选择最差的基分类器  

b 分类  

c计算分类误差率  $E_m=p(Gm(xi))\neq y_i$

d 计算 $G_m$ 的系数，也就是最终分类器的重要程度 $a_m=\frac{1}{2} \log \frac{1-E_m}{E_m}$

e: 更新样本权值分布

3 组合多个弱分类器

$f(x)=\sum a_m G_m(x)$
$G(x)=sign(f(x))$